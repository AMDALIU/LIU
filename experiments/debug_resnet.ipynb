{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd02762fd0ccae7a6827a0de0868563b3d499c815e35640ddddc3d2dc7e9a34dcb9",
   "display_name": "Python 3.6.12 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import importlib\n",
    "import models.transunet as vit\n",
    "import models.decoder_layers as decoder_layers\n",
    "import models.decoder_layers as encoder_layers\n",
    "import models.utils as ut\n",
    "import experiments.config as conf\n",
    "# import data_processing.dataset_synapse as dp \n",
    "import data_processing.data_parser as dp\n",
    "import data_processing.dataset_synapse as ds\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import tensorflow_addons as tfa\n",
    "import models.resnet_v2 as res\n",
    "\n",
    "tfk = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[[ 0  1  2  3]\n   [ 4  5  6  7]]\n\n  [[ 8  9 10 11]\n   [12 13 14 15]]]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 2, 2, 4)\n",
    "x = np.arange(np.prod(input_shape)).reshape(input_shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[[[ 0  1  2  3]\n   [ 4  5  6  7]\n   [ 0  0  0  0]]\n\n  [[ 8  9 10 11]\n   [12 13 14 15]\n   [ 0  0  0  0]]\n\n  [[ 0  0  0  0]\n   [ 0  0  0  0]\n   [ 0  0  0  0]]]], shape=(1, 3, 3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "y = tf.keras.layers.ZeroPadding2D(padding=((0,1),(0,1)))(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 55, 55, 256)\n",
      "(1, 55, 55, 256)\n",
      "(1, 56, 56, 256)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 28, 28, 512)\n",
      "(1, 14, 14, 1024)\n",
      "(1, 14, 14, 1024)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 14, 14, 1024), dtype=float32, numpy=\n",
       " array([[[[1.6419067e+00, 2.8190899e-01, 1.3068233e+00, ...,\n",
       "           4.8643484e+00, 2.9882786e+00, 2.0744565e+00],\n",
       "          [0.0000000e+00, 6.2139308e-01, 1.5283296e+00, ...,\n",
       "           2.6190541e+00, 2.2097852e+00, 0.0000000e+00],\n",
       "          [6.2280470e-01, 6.7247808e-01, 2.5756317e-01, ...,\n",
       "           5.1654224e+00, 5.8694065e-01, 3.7248759e+00],\n",
       "          ...,\n",
       "          [4.1673059e+00, 3.1737103e+00, 2.4511485e+00, ...,\n",
       "           4.2539368e+00, 2.2410641e+00, 2.0529838e+00],\n",
       "          [4.9839492e+00, 2.3349152e+00, 4.1883726e+00, ...,\n",
       "           1.2408931e+00, 1.4827459e+00, 7.3704934e-01],\n",
       "          [1.5628650e+00, 1.6329346e+00, 7.0511410e-04, ...,\n",
       "           7.7005374e-01, 2.7080584e+00, 2.6518226e-02]],\n",
       " \n",
       "         [[4.0344685e-01, 5.6608373e-01, 7.7309084e-01, ...,\n",
       "           1.6268787e+00, 5.2690897e+00, 6.6452593e-01],\n",
       "          [3.8695159e+00, 4.6216879e+00, 2.6304522e+00, ...,\n",
       "           2.4257534e+00, 1.3633397e+00, 1.4925465e-01],\n",
       "          [2.1403427e+00, 4.9078798e+00, 0.0000000e+00, ...,\n",
       "           2.0587096e+00, 2.3307648e+00, 4.3285346e-01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 2.4314284e+00, 7.0231328e+00, ...,\n",
       "           2.4574504e+00, 9.3270040e-01, 2.4358130e+00],\n",
       "          [3.5638299e+00, 1.7513499e-01, 2.6473173e-01, ...,\n",
       "           0.0000000e+00, 0.0000000e+00, 8.3608240e-01],\n",
       "          [4.1038036e+00, 9.5017308e-01, 2.1637528e+00, ...,\n",
       "           1.1219066e+00, 3.5701314e-01, 2.9142082e-01]],\n",
       " \n",
       "         [[4.0449481e+00, 3.5381004e-01, 2.4796190e+00, ...,\n",
       "           3.8729599e+00, 3.2031028e+00, 7.3353302e-01],\n",
       "          [7.2895980e-01, 1.3418550e+00, 1.4275123e+00, ...,\n",
       "           3.7043703e+00, 0.0000000e+00, 1.2469990e+00],\n",
       "          [2.0234797e+00, 0.0000000e+00, 6.4030857e+00, ...,\n",
       "           3.1289217e+00, 1.2233398e+00, 2.9400690e+00],\n",
       "          ...,\n",
       "          [2.9906795e+00, 2.9317484e+00, 0.0000000e+00, ...,\n",
       "           8.1531751e-01, 3.7838767e+00, 0.0000000e+00],\n",
       "          [2.1491907e+00, 0.0000000e+00, 3.3023338e+00, ...,\n",
       "           9.7661972e-01, 2.8323679e+00, 2.9341621e+00],\n",
       "          [1.3694253e+00, 3.0606103e-01, 5.4393539e+00, ...,\n",
       "           0.0000000e+00, 1.3332800e+00, 1.1501882e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4.7465496e+00, 4.0215745e+00, 1.5361917e-01, ...,\n",
       "           1.9393318e+00, 4.4050485e-02, 1.2675487e+00],\n",
       "          [1.6449814e+00, 3.1055992e+00, 1.7522881e+00, ...,\n",
       "           4.0227737e+00, 6.6361740e-02, 1.6175534e+00],\n",
       "          [1.5434077e+00, 2.4231000e+00, 4.4394674e+00, ...,\n",
       "           3.2861714e+00, 1.1686149e+00, 5.0248909e-01],\n",
       "          ...,\n",
       "          [1.8070450e+00, 6.1995702e+00, 2.1547816e+00, ...,\n",
       "           0.0000000e+00, 0.0000000e+00, 2.0442355e+00],\n",
       "          [1.9011576e+00, 9.8010528e-01, 0.0000000e+00, ...,\n",
       "           2.0052552e-02, 1.9047402e+00, 3.2364457e+00],\n",
       "          [0.0000000e+00, 3.5989199e+00, 6.6096687e+00, ...,\n",
       "           9.4027114e-01, 0.0000000e+00, 3.7610579e+00]],\n",
       " \n",
       "         [[2.1810853e-01, 5.4593652e-01, 9.8072863e-01, ...,\n",
       "           1.0670201e+00, 2.7599714e+00, 2.3969455e+00],\n",
       "          [0.0000000e+00, 4.1510606e-01, 3.5181651e-01, ...,\n",
       "           1.4860029e+00, 1.0635846e+00, 1.0397303e-01],\n",
       "          [1.0371885e+00, 1.1161410e+00, 2.4204836e+00, ...,\n",
       "           2.4194760e+00, 2.8156471e-01, 2.1864739e-01],\n",
       "          ...,\n",
       "          [2.4001103e-02, 9.1838360e-01, 3.7418089e+00, ...,\n",
       "           2.8788161e+00, 5.8638549e-01, 4.0239935e+00],\n",
       "          [0.0000000e+00, 6.8992071e+00, 1.7248503e+00, ...,\n",
       "           8.9844489e-01, 2.2746470e+00, 3.4327016e+00],\n",
       "          [2.1768532e+00, 1.2359402e+00, 1.3631227e+00, ...,\n",
       "           1.8490453e+00, 9.8241895e-01, 2.8250365e+00]],\n",
       " \n",
       "         [[2.5733986e+00, 2.3516808e+00, 0.0000000e+00, ...,\n",
       "           6.3762999e-01, 7.2588235e-01, 4.7639531e-01],\n",
       "          [0.0000000e+00, 3.1795900e+00, 2.5056281e+00, ...,\n",
       "           1.4481601e-01, 5.9519756e-01, 3.4162912e+00],\n",
       "          [3.7227533e+00, 3.6995692e+00, 3.3677542e-01, ...,\n",
       "           0.0000000e+00, 4.0761888e-02, 0.0000000e+00],\n",
       "          ...,\n",
       "          [0.0000000e+00, 4.7445064e+00, 3.1110411e+00, ...,\n",
       "           3.6487238e+00, 3.1791884e-01, 0.0000000e+00],\n",
       "          [1.8626872e+00, 6.5872955e-01, 9.3025279e-01, ...,\n",
       "           1.8297062e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 4.6796231e+00, 2.8832364e+00, ...,\n",
       "           1.2884905e+00, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1, 28, 28, 512), dtype=float32, numpy=\n",
       "  array([[[[0.03626752, 1.697257  , 0.23500656, ..., 1.1172379 ,\n",
       "            0.88208616, 0.64129686],\n",
       "           [0.        , 0.        , 0.        , ..., 1.6897924 ,\n",
       "            0.        , 0.        ],\n",
       "           [0.1772444 , 0.        , 0.6833843 , ..., 0.50920904,\n",
       "            0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 1.3578808 , ..., 1.0190053 ,\n",
       "            1.4669611 , 0.        ],\n",
       "           [1.0451254 , 0.        , 0.        , ..., 0.4268862 ,\n",
       "            0.        , 1.3807682 ],\n",
       "           [2.0002584 , 0.75946754, 0.        , ..., 0.        ,\n",
       "            0.        , 0.29157093]],\n",
       "  \n",
       "          [[0.        , 0.7899433 , 0.        , ..., 1.4982818 ,\n",
       "            0.55097294, 0.        ],\n",
       "           [1.9340806 , 0.        , 0.        , ..., 0.        ,\n",
       "            0.56546515, 0.        ],\n",
       "           [0.        , 0.60694134, 0.4802532 , ..., 0.558919  ,\n",
       "            0.33273077, 0.        ],\n",
       "           ...,\n",
       "           [0.08034968, 2.1182413 , 0.        , ..., 0.        ,\n",
       "            0.381278  , 0.        ],\n",
       "           [0.        , 0.89082825, 1.1361655 , ..., 0.64390373,\n",
       "            1.7288787 , 0.        ],\n",
       "           [0.9006431 , 1.0965519 , 0.        , ..., 0.        ,\n",
       "            0.14199543, 0.        ]],\n",
       "  \n",
       "          [[0.00467041, 1.29586   , 0.        , ..., 0.43224877,\n",
       "            0.        , 1.6090369 ],\n",
       "           [2.0012312 , 1.4293888 , 2.7316763 , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [0.94206977, 0.        , 1.613759  , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           ...,\n",
       "           [1.0001761 , 0.        , 0.        , ..., 0.        ,\n",
       "            0.294771  , 1.1422962 ],\n",
       "           [0.7881634 , 0.16014042, 0.16192791, ..., 0.        ,\n",
       "            0.733286  , 0.        ],\n",
       "           [0.03709814, 0.14924952, 2.4109244 , ..., 0.        ,\n",
       "            1.8079056 , 1.4948655 ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.        , 0.        , 0.62197936, ..., 2.0177212 ,\n",
       "            0.        , 1.0501524 ],\n",
       "           [0.        , 0.33176517, 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [1.0193279 , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 2.7902746 ],\n",
       "           ...,\n",
       "           [0.        , 0.91058314, 0.        , ..., 1.8312079 ,\n",
       "            1.4176984 , 0.        ],\n",
       "           [0.968289  , 0.        , 0.6965713 , ..., 0.4375842 ,\n",
       "            0.43235475, 1.1569705 ],\n",
       "           [1.916831  , 2.7224317 , 1.4380684 , ..., 2.129994  ,\n",
       "            0.93785393, 0.        ]],\n",
       "  \n",
       "          [[0.04324213, 0.        , 0.        , ..., 1.0048832 ,\n",
       "            0.        , 0.        ],\n",
       "           [1.7819632 , 0.        , 0.3840102 , ..., 0.9250102 ,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 1.5698321 ,\n",
       "            0.        , 0.6274437 ],\n",
       "           ...,\n",
       "           [2.3308578 , 1.6838102 , 0.        , ..., 0.        ,\n",
       "            0.        , 0.45912504],\n",
       "           [0.        , 0.        , 0.        , ..., 0.43727273,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 1.6380707 , ..., 2.0977201 ,\n",
       "            0.8401234 , 0.10843888]],\n",
       "  \n",
       "          [[0.        , 1.4973962 , 0.        , ..., 0.        ,\n",
       "            0.5093138 , 0.        ],\n",
       "           [0.27023047, 0.        , 0.8466748 , ..., 0.88262284,\n",
       "            0.        , 0.62332195],\n",
       "           [0.19782513, 0.        , 0.6583518 , ..., 0.        ,\n",
       "            1.0018097 , 0.        ],\n",
       "           ...,\n",
       "           [1.0581846 , 0.        , 0.6973279 , ..., 0.9216027 ,\n",
       "            0.89950705, 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.5026201 ,\n",
       "            1.2262425 , 0.        ],\n",
       "           [0.        , 0.        , 0.24118069, ..., 0.        ,\n",
       "            0.        , 0.        ]]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1, 56, 56, 256), dtype=float32, numpy=\n",
       "  array([[[[0.3571218 , 1.16497   , 0.7107158 , ..., 0.45372194,\n",
       "            0.6754699 , 0.        ],\n",
       "           [0.13870831, 1.0482247 , 0.        , ..., 0.95309395,\n",
       "            0.776381  , 0.        ],\n",
       "           [2.0272183 , 0.10461805, 0.        , ..., 1.5956736 ,\n",
       "            0.37340885, 0.        ],\n",
       "           ...,\n",
       "           [0.16664314, 1.0280716 , 1.0808415 , ..., 0.6489619 ,\n",
       "            0.        , 1.0548462 ],\n",
       "           [0.        , 0.12019692, 0.        , ..., 1.1065865 ,\n",
       "            0.21698883, 0.05167511],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          [[0.13488792, 3.9708602 , 0.        , ..., 1.5401225 ,\n",
       "            0.        , 0.10485673],\n",
       "           [0.75676847, 1.0155795 , 0.        , ..., 0.9939336 ,\n",
       "            0.        , 2.5990443 ],\n",
       "           [0.09673458, 2.5612302 , 0.975328  , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.45590705, ..., 1.3407454 ,\n",
       "            0.        , 0.39304194],\n",
       "           [0.67315394, 1.2206163 , 0.        , ..., 0.7649586 ,\n",
       "            0.695281  , 1.676231  ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          [[0.6978089 , 0.52625465, 2.9282877 , ..., 2.6501768 ,\n",
       "            0.1652465 , 2.0979075 ],\n",
       "           [0.        , 1.4442928 , 1.8140354 , ..., 1.1139344 ,\n",
       "            0.09585381, 1.9643815 ],\n",
       "           [0.8832415 , 2.912935  , 0.5651809 , ..., 2.0129178 ,\n",
       "            0.00964618, 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.97743803, 0.        , ..., 0.6262673 ,\n",
       "            1.5729798 , 1.1337159 ],\n",
       "           [0.73055047, 0.9258858 , 2.2457566 , ..., 1.1362017 ,\n",
       "            0.21035472, 1.6160723 ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.74020475, 0.        , 1.1448133 , ..., 0.6056302 ,\n",
       "            0.02980191, 0.31978092],\n",
       "           [0.363501  , 1.1077257 , 1.1648657 , ..., 1.4313922 ,\n",
       "            0.38841712, 0.82113785],\n",
       "           [2.7066789 , 1.5141509 , 0.        , ..., 0.        ,\n",
       "            1.5343595 , 4.2116675 ],\n",
       "           ...,\n",
       "           [0.70436317, 1.7034781 , 0.9599812 , ..., 0.        ,\n",
       "            0.        , 3.2029476 ],\n",
       "           [0.7498801 , 2.0534792 , 1.294729  , ..., 3.3105528 ,\n",
       "            1.7895373 , 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          [[2.6922011 , 0.64033794, 0.        , ..., 0.44227254,\n",
       "            0.        , 3.9695423 ],\n",
       "           [1.493844  , 0.        , 0.        , ..., 0.5251579 ,\n",
       "            0.        , 0.7787272 ],\n",
       "           [1.1653304 , 0.4151168 , 0.18542162, ..., 0.        ,\n",
       "            0.7026143 , 3.315603  ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.986657  , ..., 0.        ,\n",
       "            1.4451663 , 2.4394453 ],\n",
       "           [0.0374009 , 0.        , 1.4097306 , ..., 0.6685485 ,\n",
       "            0.25507373, 1.177021  ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]]]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(1, 112, 112, 64), dtype=float32, numpy=\n",
       "  array([[[[0.07226605, 0.09230728, 1.2964994 , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [1.0235122 , 0.        , 1.2250613 , ..., 0.        ,\n",
       "            0.        , 0.6624403 ],\n",
       "           [0.2648053 , 0.42903653, 0.        , ..., 0.25487617,\n",
       "            1.7130598 , 1.328342  ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        , ..., 0.05185517,\n",
       "            0.10787337, 0.        ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.8149481 , 0.38500202],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.69559735, 1.1917914 ]],\n",
       "  \n",
       "          [[1.4582307 , 0.        , 0.88688976, ..., 0.5072009 ,\n",
       "            1.196477  , 0.4327427 ],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           [1.1456959 , 0.        , 0.7313966 , ..., 0.        ,\n",
       "            0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.09838471, 0.2797886 , 0.        , ..., 1.5500832 ,\n",
       "            0.        , 1.093531  ],\n",
       "           [0.3740359 , 1.1460482 , 0.        , ..., 0.        ,\n",
       "            1.3533372 , 0.46416032],\n",
       "           [0.4434177 , 0.516719  , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          [[0.        , 0.        , 1.2154976 , ..., 0.05982896,\n",
       "            0.        , 0.9872232 ],\n",
       "           [0.39380357, 0.        , 0.        , ..., 2.4120085 ,\n",
       "            1.7680316 , 0.12552261],\n",
       "           [0.9502781 , 0.4592227 , 0.        , ..., 0.24226004,\n",
       "            0.        , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.        , 0.52315825],\n",
       "           [1.6880628 , 1.2564702 , 0.        , ..., 0.        ,\n",
       "            1.3173616 , 0.        ],\n",
       "           [0.        , 1.5403683 , 0.        , ..., 0.        ,\n",
       "            0.        , 0.        ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[2.8702888 , 0.        , 1.9445908 , ..., 0.        ,\n",
       "            0.9532695 , 1.5866859 ],\n",
       "           [0.        , 0.        , 0.51840585, ..., 0.5811491 ,\n",
       "            0.        , 0.        ],\n",
       "           [0.        , 0.        , 1.2972432 , ..., 0.689251  ,\n",
       "            0.        , 1.2297128 ],\n",
       "           ...,\n",
       "           [1.4410073 , 0.95770794, 0.        , ..., 0.1797706 ,\n",
       "            0.        , 0.12847446],\n",
       "           [1.7565969 , 0.69989604, 0.        , ..., 0.        ,\n",
       "            0.        , 1.0914989 ],\n",
       "           [0.        , 0.5575379 , 0.        , ..., 0.        ,\n",
       "            0.13211034, 0.8005518 ]],\n",
       "  \n",
       "          [[2.7942529 , 0.24492185, 1.226851  , ..., 0.5283484 ,\n",
       "            1.9191881 , 0.7935195 ],\n",
       "           [0.        , 0.48790017, 0.        , ..., 0.        ,\n",
       "            1.1008228 , 0.        ],\n",
       "           [0.42322144, 0.20553832, 0.3139587 , ..., 0.        ,\n",
       "            1.0835639 , 0.        ],\n",
       "           ...,\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.04756421, 0.08054037],\n",
       "           [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "            0.74025685, 0.        ],\n",
       "           [0.        , 1.395153  , 0.        , ..., 0.        ,\n",
       "            0.48433605, 1.3303777 ]],\n",
       "  \n",
       "          [[0.5699857 , 0.        , 1.5216811 , ..., 0.        ,\n",
       "            1.4539245 , 0.57913584],\n",
       "           [1.5591388 , 0.03096452, 0.        , ..., 0.08410855,\n",
       "            0.        , 0.        ],\n",
       "           [0.58031416, 0.14733368, 0.        , ..., 0.        ,\n",
       "            1.4168365 , 0.45387536],\n",
       "           ...,\n",
       "           [0.82799894, 0.        , 0.        , ..., 0.        ,\n",
       "            0.30648068, 0.        ],\n",
       "           [0.67335665, 0.        , 0.        , ..., 0.35389435,\n",
       "            0.        , 0.        ],\n",
       "           [0.15286997, 0.        , 0.        , ..., 0.        ,\n",
       "            0.21390206, 0.        ]]]], dtype=float32)>])"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "importlib.reload(res)\n",
    "model = res.ResNetV2([3,4,9])\n",
    "model(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'ResNetV2' object has no attribute 'summary'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ResNetV2' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ds.load_data(\"../data/train_npz/\", 10, output_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 384, 384, 3)\n(10, 384, 384, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tfk.applications.ResNet50V2(include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([7, 7, 3, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "w = resnet.get_layer('conv1_conv').weights[0]\n",
    "m, v = tf.nn.moments(w, axes=[0,1,2], keepdims=True) \n",
    "w = (w-m) / tf.sqrt(v+1e-5)\n",
    "tf.math.is_nan(w)\n",
    "w.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdConv2D(tfkl.Conv2D):\n",
    "    \n",
    "    def call(self, x):\n",
    "        w = self.weights[0]\n",
    "        m, v = tf.nn.moments(w, axes=[0,1,2], keepdims=True) \n",
    "        w = (w-m) / tf.sqrt(v+1e-5)\n",
    "        # self.weights = w \n",
    "        return tf.nn.conv2d(x, w, self.strides, self.padding.upper(), \"NHWC\" if self.data_format == \"channels_last\" else \"NCHW\", self.dilation_rate, self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = StdConv2D(filters=64, kernel_size=7, strides=2, padding=\"same\")\n",
    "dummy = np.random.rand(1,224,224,3)\n",
    "# conv(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 23,519,360\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(conf)\n",
    "importlib.reload(decoder_layers)\n",
    "importlib.reload(encoder_layers)\n",
    "importlib.reload(vit)\n",
    "importlib.reload(ut)\n",
    "config = conf.get_r50_b16()\n",
    "trans = vit.TransUnet(config)\n",
    "trans.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x000001D3F0393D90>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Logiciel\\anaconda\\envs\\tf-keras-gpu\\lib\\weakref.py\", line 357, in remove\n",
      "    self = selfref()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "trans.model.fit(x=X, y=y, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(conf)\n",
    "importlib.reload(decoder_layers)\n",
    "importlib.reload(encoder_layers)\n",
    "importlib.reload(vit)\n",
    "importlib.reload(ut)\n",
    "config = conf.get_b16_none()\n",
    "trans = vit.TransUnet(config)\n",
    "trans.compile()"
   ]
  }
 ]
}