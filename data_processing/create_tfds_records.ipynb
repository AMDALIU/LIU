{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "create_tfds_records.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6PiptPkfw0O",
        "outputId": "d2d6a070-0cc5-4418-d583-34f8d4b29a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install -q tensorflow-io"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 25.4MB 159kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZgRQSIf0-t"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import importlib\n",
        "import yaml\n",
        "import cv2 \n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYb7qcMdmvOD",
        "outputId": "8879933f-07de-4d98-ba98-4936b6ebe7ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeOwfrmPgRHi",
        "outputId": "ba998ef1-f274-4943-9423-9183562c1cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/KTH/DD2424/tran-unet.json' \n",
        "!echo $GOOGLE_APPLICATION_CREDENTIALS\n",
        "\n",
        "project='dd2424-308314' # change to your project name here\n",
        "os.environ['GCP_PROJECT'] = project \n",
        "os.environ['GCP_ACCOUNT'] = 'trans-unet@' + project + '.iam.gserviceaccount.com'\n",
        "\n",
        "!gcloud auth activate-service-account \"$GCP_ACCOUNT\" --key-file=\"$GOOGLE_APPLICATION_CREDENTIALS\" --project=\"$GCP_PROJECT\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/KTH/DD2424/tran-unet.json\n",
            "Activated service account credentials for: [trans-unet@dd2424-308314.iam.gserviceaccount.com]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLFLoUM8gVX5",
        "outputId": "33cced95-dd59-484b-bf0d-d9d9472d391b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0   103k      0 --:--:-- --:--:-- --:--:--  103k\n",
            "OK\n",
            "85 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.35.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 85 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsPjvXn3gagl",
        "outputId": "ccbc132c-98f9-413a-c6cb-acb6bbbd45c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir DataSet\n",
        "!gcsfuse --implicit-dirs aga_bucket DataSet"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘DataSet’: File exists\n",
            "2021/05/04 19:11:15.819947 Using mount point: /content/DataSet\n",
            "2021/05/04 19:11:15.828446 Opening GCS connection...\n",
            "2021/05/04 19:11:16.578298 Mounting file system \"aga_bucket\"...\n",
            "2021/05/04 19:11:16.578844 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJDhwoKGgv9M",
        "outputId": "f7e5cfe2-13b8-40b4-b7d6-1cd532eddbae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /content/DataSet"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "synapse-tfrecords  test_vol_h5\ttrain_npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF7NMaOTytlB"
      },
      "source": [
        "## Write image to tfrecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5GXOSJGy0HK"
      },
      "source": [
        "data = np.load('DataSet/train_npz/case0005_slice000.npz')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n0tdbgj5McD"
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n",
        "        value = value.numpy() # get value of tensor\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a floast_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_zQrrvC0PxJ"
      },
      "source": [
        "def parse_single_image(image, label):\n",
        "  \n",
        "  #define the dictionary -- the structure -- of our single example\n",
        "  data = {\n",
        "        'height' : _int64_feature(image.shape[0]),\n",
        "        'width' : _int64_feature(image.shape[1]),\n",
        "        'depth' : _int64_feature(image.shape[2]),\n",
        "        'image' : _bytes_feature(serialize_array(image)),\n",
        "        'label' : _bytes_feature(serialize_array(label))\n",
        "    }\n",
        "  #create an Example, wrapping the single features\n",
        "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
        "\n",
        "  return out"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oissgJMm5qA6"
      },
      "source": [
        "def write_image_to_tfr(image, label, filename:str=\"images\"):\n",
        "  \n",
        "  filename= filename+\".tfrecords\"\n",
        "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n",
        "\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "  print(image_rgb.shape)\n",
        "  out = parse_single_image(image=image_rgb, label=label)\n",
        "  writer.write(out.SerializeToString())\n",
        "\n",
        "  writer.close()\n",
        "  print(f\"Wrote {filename} elements to TFRecord\")"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-wl6GqJ6rXg",
        "outputId": "4acffded-d5d6-4968-b211-8761f0f44ba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "write_image_to_tfr_short(data['image'], data['label'], filename='case0005_slice000')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote case0005_slice000.tfrecords elements to TFRecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu4Ork-F2ADr",
        "outputId": "5a6bc05d-522d-45e2-ac02-a417c976cda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!du -sh case0005_slice000.tfrecords"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.1M\tcase0005_slice000.tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2WmUJbl2E96",
        "outputId": "4fc585d2-d0c5-44d9-88ff-11ec55f78daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!du -sh 'DataSet/train_npz/case0005_slice000.npz'"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1M\tDataSet/train_npz/case0005_slice000.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3t2zn732LWb"
      },
      "source": [
        "## Read a TFRecord file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow3H9nBc7OBA"
      },
      "source": [
        "def parse_tfr_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'label':tf.io.FixedLenFeature([], tf.string),\n",
        "      'image' : tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "\n",
        "    \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "  \n",
        "  height = content['height']\n",
        "  width = content['width']\n",
        "  depth = content['depth']\n",
        "  raw_label = content['label']\n",
        "  raw_image = content['image']\n",
        "  \n",
        "  \n",
        "  image = tf.io.parse_tensor(raw_image, out_type=tf.float32)\n",
        "  image = tf.reshape(image, shape=[height,width,depth])\n",
        "\n",
        "  label = tf.io.parse_tensor(raw_label, out_type=tf.float32)\n",
        "  image = tf.reshape(label, shape=[height,width])\n",
        "  return (image, label)\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1wzuZxp7lfs",
        "outputId": "d128b868-48c0-4389-d0d5-ae84429fcf5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data['label'].dtype"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMdnAYlp7KLG"
      },
      "source": [
        "filename=\"case0005_slice000.tfrecords\""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wKjUTqk2J_x"
      },
      "source": [
        "def get_dataset_small(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(\n",
        "      parse_tfr_element\n",
        "  )\n",
        "    \n",
        "  return dataset"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ZkhtvJ8fs-",
        "outputId": "d8787b1f-7508-42a8-9c4f-8161cb198883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_small = get_dataset_small(filename)\n",
        "\n",
        "for sample in dataset_small.take(1):\n",
        "  print(sample)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(512, 512), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(512, 512), dtype=float32, numpy=\n",
            "array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}