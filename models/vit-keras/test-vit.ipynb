{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd02762fd0ccae7a6827a0de0868563b3d499c815e35640ddddc3d2dc7e9a34dcb9",
   "display_name": "Python 3.6.12 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vit as vit\n",
    "import importlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AddPositionEmbs (None, 1024, 768)\n",
      "KeysView(<numpy.lib.npyio.NpzFile object at 0x000001FD00BD7FD0>)\n",
      "Transformer/posembed_input Source (1, 577, 768) Target <layers.AddPositionEmbs object at 0x000001FD0C0D2A58>\n",
      "WEIGHTS SIZE [<tf.Variable 'Transformer/posembed_input/pos_embedding:0' shape=(1, 1024, 768) dtype=float32, numpy=\n",
      "array([[[-0.00961231,  0.10021357, -0.00916442, ...,  0.05917924,\n",
      "          0.0279368 ,  0.02624457],\n",
      "        [ 0.03108776, -0.13621484,  0.00896925, ..., -0.02995931,\n",
      "         -0.00030063, -0.08659324],\n",
      "        [ 0.06705414, -0.04718886, -0.14097714, ...,  0.00806028,\n",
      "          0.04190693, -0.0045358 ],\n",
      "        ...,\n",
      "        [-0.00632004, -0.05909134,  0.06750621, ...,  0.01567007,\n",
      "         -0.06268021,  0.02405779],\n",
      "        [-0.07391153, -0.01527772, -0.01696049, ..., -0.06948536,\n",
      "         -0.07662233,  0.0542371 ],\n",
      "        [ 0.04770564, -0.00070555, -0.00588146, ..., -0.11100532,\n",
      "         -0.09508401, -0.00932442]]], dtype=float32)>]\n",
      "d:\\insa\\5if\\KTH\\P4\\DL\\Project\\TransUnet\\vit-keras\\vit_keras\\utils.py:72: UserWarning: Resizing position embeddings from 24 to 31\n",
      "  UserWarning,\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Layer weight shape (1, 1024, 768) not compatible with provided weight shape (1, 962, 768)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ce3e6a2c7358>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvit_b16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\insa\\5if\\KTH\\P4\\DL\\Project\\TransUnet\\vit-keras\\vit_keras\\vit.py\u001b[0m in \u001b[0;36mvit_b16\u001b[1;34m(image_size, pretrained, weights)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         load_pretrained(\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"B_16\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         )\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\insa\\5if\\KTH\\P4\\DL\\Project\\TransUnet\\vit-keras\\vit_keras\\vit.py\u001b[0m in \u001b[0;36mload_pretrained\u001b[1;34m(size, weights, model)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{BASE_URL}/{fname}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mlocal_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\insa\\5if\\KTH\\P4\\DL\\Project\\TransUnet\\vit-keras\\vit_keras\\utils.py\u001b[0m in \u001b[0;36mload_weights_numpy\u001b[1;34m(model, params_path)\u001b[0m\n\u001b[0;32m    174\u001b[0m     apply_embedding_weights(\n\u001b[0;32m    175\u001b[0m         \u001b[0mtarget_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Transformer/posembed_input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0msource_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Transformer/posembed_input/pos_embedding\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m     \u001b[0msource_keys_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Transformer/posembed_input/pos_embedding\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\insa\\5if\\KTH\\P4\\DL\\Project\\TransUnet\\vit-keras\\vit_keras\\utils.py\u001b[0m in \u001b[0;36mapply_embedding_weights\u001b[1;34m(target_layer, source_weights)\u001b[0m\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m         \u001b[0msource_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mtarget_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Logiciel\\anaconda\\envs\\tf-keras-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1871\u001b[0m           raise ValueError(\n\u001b[0;32m   1872\u001b[0m               \u001b[1;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m               'shape %s' % (ref_shape, weight.shape))\n\u001b[0m\u001b[0;32m   1874\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m         \u001b[0mweight_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (1, 1024, 768) not compatible with provided weight shape (1, 962, 768)"
     ]
    }
   ],
   "source": [
    "importlib.reload(vit)\n",
    "image_size=512\n",
    "model = vit.vit_b16(image_size, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load(\"C:/Users/utilisateur/.keras/weights/ViT-B_16_imagenet21k+imagenet2012.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Transformer/encoder_norm/bias',\n",
       " 'Transformer/encoder_norm/scale',\n",
       " 'Transformer/encoderblock_0/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_0/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_0/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_0/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_0/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_0/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_0/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_0/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_0/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_1/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_1/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_1/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_1/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_1/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_1/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_1/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_1/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_1/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_10/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_10/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_10/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_10/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_10/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_10/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_10/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_10/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_10/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_11/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_11/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_11/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_11/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_11/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_11/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_11/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_11/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_11/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_2/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_2/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_2/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_2/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_2/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_2/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_2/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_2/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_2/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_3/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_3/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_3/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_3/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_3/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_3/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_3/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_3/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_3/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_4/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_4/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_4/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_4/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_4/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_4/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_4/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_4/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_4/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_5/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_5/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_5/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_5/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_5/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_5/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_5/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_5/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_5/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_6/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_6/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_6/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_6/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_6/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_6/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_6/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_6/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_6/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_7/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_7/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_7/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_7/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_7/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_7/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_7/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_7/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_7/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_8/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_8/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_8/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_8/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_8/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_8/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_8/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_8/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_8/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/encoderblock_9/LayerNorm_0/bias',\n",
       " 'Transformer/encoderblock_9/LayerNorm_0/scale',\n",
       " 'Transformer/encoderblock_9/LayerNorm_2/bias',\n",
       " 'Transformer/encoderblock_9/LayerNorm_2/scale',\n",
       " 'Transformer/encoderblock_9/MlpBlock_3/Dense_0/bias',\n",
       " 'Transformer/encoderblock_9/MlpBlock_3/Dense_0/kernel',\n",
       " 'Transformer/encoderblock_9/MlpBlock_3/Dense_1/bias',\n",
       " 'Transformer/encoderblock_9/MlpBlock_3/Dense_1/kernel',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/key/bias',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/key/kernel',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/out/bias',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/out/kernel',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/query/bias',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/query/kernel',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/value/bias',\n",
       " 'Transformer/encoderblock_9/MultiHeadDotProductAttention_1/value/kernel',\n",
       " 'Transformer/posembed_input/pos_embedding',\n",
       " 'cls',\n",
       " 'embedding/bias',\n",
       " 'embedding/kernel',\n",
       " 'head/bias',\n",
       " 'head/kernel']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "weights.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16, 16, 3, 768)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "weights[\"embedding/kernel\"].shape"
   ]
  }
 ]
}